import type { NextRequest } from "next/server";
import { NextResponse } from "next/server";
import { z } from "zod";

// –£–±–∏—Ä–∞–µ–º –∏–º–ø–æ—Ä—Ç generateVideoWithStrategy –∏ —Å–æ–∑–¥–∞–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
import {
  getSuperduperAIConfig,
  configureSuperduperAI,
} from "@/lib/config/superduperai";

// –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å session data
import { getSessionData, type SessionData } from "@/lib/kv";

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å SuperDuperAI API
async function generateVideoWithSuperDuperAI(
  prompt: string,
  modelName: string,
  modelConfig?: {
    width?: number;
    height?: number;
    aspectRatio?: string;
    duration?: number;
    frameRate?: number;
    style?: string;
    shotSize?: string;
  },
  imageFile?: File,
  generationType: "text-to-video" | "image-to-video" = "text-to-video"
): Promise<{ success: boolean; fileId?: string; error?: string }> {
  console.log("üé¨ Starting video generation with SuperDuperAI:", {
    prompt,
    modelName,
    modelConfig,
  });

  try {
    // –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º SuperDuperAI –∫–ª–∏–µ–Ω—Ç
    configureSuperduperAI();
    const config = getSuperduperAIConfig();

    // –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
    const mappedModelName = mapModelNameToConfig(modelName, generationType);
    const finalConfig = {
      generation_config_name: mappedModelName,
      width: modelConfig?.width ?? 1280,
      height: modelConfig?.height ?? 720,
      aspectRatio: modelConfig?.aspectRatio ?? "16:9",
      duration: modelConfig?.duration ?? 8,
      frameRate: modelConfig?.frameRate ?? 30,
      style: modelConfig?.style ?? "flux_watercolor",
      shotSize: modelConfig?.shotSize ?? "medium_shot",
    };

    // –ï—Å–ª–∏ –µ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∑–∞–≥—Ä—É–∂–∞–µ–º –µ–≥–æ –≤ SuperDuperAI
    let imageFileId: string | undefined;
    if (imageFile && generationType === "image-to-video") {
      console.log("üñºÔ∏è Image file provided for image-to-video generation:", {
        fileName: imageFile.name,
        fileSize: imageFile.size,
        fileType: imageFile.type,
      });

      try {
        // –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ SuperDuperAI
        const imageFormData = new FormData();
        imageFormData.append("payload", imageFile, imageFile.name);
        imageFormData.append("type", "image");

        const imageUploadResponse = await fetch(
          `${config.url}/api/v1/file/upload`,
          {
            method: "POST",
            headers: {
              Authorization: `Bearer ${config.token}`,
              "User-Agent": "SuperDuperAI-Landing/1.0",
            },
            body: imageFormData,
          }
        );

        if (imageUploadResponse.ok) {
          const imageUploadResult = await imageUploadResponse.json();
          imageFileId = imageUploadResult.id;
          console.log("‚úÖ Image uploaded successfully, file ID:", imageFileId);
        } else {
          console.error(
            "‚ùå Failed to upload image:",
            await imageUploadResponse.text()
          );
        }
      } catch (error) {
        console.error("‚ùå Error uploading image:", error);
      }
    }

    // –°–æ–∑–¥–∞–µ–º payload –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    const payload = {
      type: "media",
      template_name: null,
      config: {
        prompt,
        negative_prompt: "",
        width: finalConfig.width || 1280,
        height: finalConfig.height || 720,
        aspect_ratio: finalConfig.aspectRatio || "16:9",
        duration: finalConfig.duration || 8,
        frame_rate: finalConfig.frameRate || 30,
        shot_size: finalConfig.shotSize || "medium_shot",
        style_name: finalConfig.style || "flux_watercolor",
        seed: Math.floor(Math.random() * 1000000000000),
        generation_config_name: finalConfig.generation_config_name,
        entity_ids: [],
        references: imageFileId
          ? [
              {
                type: "source",
                reference_id: imageFileId,
              },
            ]
          : ([] as string[]),
      },
    };

    console.log(
      "üì§ Sending video generation request to SuperDuperAI:",
      payload
    );

    const response = await fetch(`${config.url}/api/v1/file/generate-video`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${config.token}`,
        "User-Agent": "SuperDuperAI-Landing/1.0",
      },
      body: JSON.stringify(payload),
    });

    console.log(`üì° SuperDuperAI API Response Status: ${response.status}`);

    if (!response.ok) {
      const errorText = await response.text();
      console.error("‚ùå SuperDuperAI API Error:", errorText);
      return { success: false, error: errorText };
    }

    const result = await response.json();
    console.log("üì® Video generation API Response:", result);

    if (result.id) {
      console.log("üé¨ Video generation started - FileId:", result.id);
      return { success: true, fileId: result.id };
    } else {
      console.error("‚ùå No file ID in response:", result);
      return { success: false, error: "No file ID in response" };
    }
  } catch (error) {
    console.error("‚ùå Video generation error:", error);
    return {
      success: false,
      error: error instanceof Error ? error.message : "Unknown error",
    };
  }
}
import {
  saveGenerationData as saveToGlobalStore,
  loadGenerationData as loadFromGlobalStore,
  type GenerationData,
} from "@/lib/generation-store";

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –º–æ–¥–µ–ª–µ–π –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ SuperDuperAI
function mapModelNameToConfig(
  modelName: string,
  generationType: "text-to-video" | "image-to-video"
): string {
  // –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
  const normalizedModelName = modelName
    .toLowerCase()
    .replace(/\s+/g, "")
    .replace(/[^a-z0-9]/g, "");

  const modelMap: Record<string, Record<string, string>> = {
    veo2: {
      "text-to-video": "google-cloud/veo2-text2video",
      "image-to-video": "google-cloud/veo2",
    },
    veo3: {
      "text-to-video": "google-cloud/veo3-text2video",
      "image-to-video": "google-cloud/veo3",
    },
    sora: {
      "text-to-video": "azure-openai/sora",
      "image-to-video": "azure-openai/sora",
    },
    // –î–æ–±–∞–≤–ª—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    soravideo: {
      "text-to-video": "azure-openai/sora",
      "image-to-video": "azure-openai/sora",
    },
    veo2video: {
      "text-to-video": "google-cloud/veo2-text2video",
      "image-to-video": "google-cloud/veo2",
    },
    veo3video: {
      "text-to-video": "google-cloud/veo3-text2video",
      "image-to-video": "google-cloud/veo3",
    },
    // –î–æ–±–∞–≤–ª—è–µ–º –µ—â–µ –±–æ–ª—å—à–µ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    soravideogenerator: {
      "text-to-video": "azure-openai/sora",
      "image-to-video": "azure-openai/sora",
    },
    veo2videogenerator: {
      "text-to-video": "google-cloud/veo2-text2video",
      "image-to-video": "google-cloud/veo2",
    },
    veo3videogenerator: {
      "text-to-video": "google-cloud/veo3-text2video",
      "image-to-video": "google-cloud/veo3",
    },
  };

  const mappedConfig = modelMap[normalizedModelName]?.[generationType];
  console.log(
    `üéØ Model mapping: "${modelName}" -> "${normalizedModelName}" -> "${mappedConfig ?? modelName}"`
  );

  return mappedConfig ?? modelName;
}

// –°—Ö–µ–º–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å –º–æ–¥–µ–ª—å—é
const modelVideoGenerationSchema = z.object({
  generationId: z.string().optional(),
  prompt: z.string().min(1, "Prompt is required"),
  modelName: z.string().min(1, "Model name is required"),
  modelConfig: z
    .object({
      maxDuration: z.number().optional(),
      aspectRatio: z.string().optional(),
      width: z.number().optional(),
      height: z.number().optional(),
      frameRate: z.number().optional(),
    })
    .optional(),
  videoCount: z.number().min(1).max(3).default(1),
  status: z
    .enum(["pending", "processing", "completed", "error"])
    .default("pending"),
  progress: z.number().min(0).max(100).default(0),
  createdAt: z.string().optional(),
  paymentIntentId: z.string().optional(),
  sessionId: z.string().optional(),
  customerEmail: z.string().optional(),
  videos: z
    .array(
      z.object({
        fileId: z.string(),
        url: z.string().optional(),
        thumbnailUrl: z.string().optional(),
        status: z
          .enum(["pending", "processing", "completed", "error"])
          .default("processing"),
      })
    )
    .optional(),
  error: z.string().optional(),
  // –ù–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
  imageFile: z.any().optional(), // File object
  generationType: z
    .enum(["text-to-video", "image-to-video"])
    .default("text-to-video"),
  // –ù–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è –ø—Ä—è–º–æ–π –æ–ø–ª–∞—Ç—ã
  paymentSessionId: z.string().optional(),
});

type ModelVideoGenerationData = z.infer<typeof modelVideoGenerationSchema>;

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ModelVideoGenerationData –≤ GenerationData –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –≥–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
function saveVideoGenerationData(data: ModelVideoGenerationData) {
  if (!data.generationId) {
    console.warn("‚ö†Ô∏è Cannot save generation data: generationId is undefined");
    return;
  }

  const generationData: GenerationData = {
    generationId: data.generationId,
    status: data.status,
    progress: data.progress,
    prompt: data.prompt,
    modelName: data.modelName,
    modelType: "video",
    paymentSessionId: data.paymentSessionId as any,
    createdAt: data.createdAt ?? new Date().toISOString(),
    error: data.error as any,
    videoGeneration: data.videos?.[0]
      ? ({
          fileId: data.videos[0].fileId,
          status: data.videos[0].status,
          url: data.videos[0].url as any,
          thumbnailUrl: data.videos[0].thumbnailUrl as any,
        } as any)
      : undefined,
    generationType: data.generationType,
  };

  saveToGlobalStore(generationData);
  console.log(
    `üíæ Saved video generation data to global store for ${data.generationId}`
  );
}

// –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
function loadVideoGenerationData(
  generationId: string
): ModelVideoGenerationData | null {
  if (!generationId) {
    console.warn("‚ö†Ô∏è Cannot load generation data: generationId is undefined");
    return null;
  }

  const globalData = loadFromGlobalStore(generationId);
  if (!globalData) {
    console.log(
      `üìÇ No generation data found in global store for ${generationId}`
    );
    return null;
  }

  // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ ModelVideoGenerationData
  const localData: ModelVideoGenerationData = {
    generationId: globalData.generationId,
    prompt: globalData.prompt,
    modelName: globalData.modelName,
    status: globalData.status,
    progress: globalData.progress,
    createdAt: globalData.createdAt ?? new Date().toISOString(),
    paymentSessionId: globalData.paymentSessionId,
    videoCount: 1, // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    generationType:
      (globalData.generationType as "text-to-video" | "image-to-video") ??
      "text-to-video",
    videos: globalData.videoGeneration
      ? [
          {
            fileId: globalData.videoGeneration.fileId,
            status: globalData.videoGeneration.status,
            url: globalData.videoGeneration.url,
            thumbnailUrl: globalData.videoGeneration.thumbnailUrl,
          },
        ]
      : [],
  };

  console.log(
    `üìÇ Loaded video generation data from global store for ${generationId}`
  );
  return localData;
}

// POST - –°–æ–∑–¥–∞–µ–º/–∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤–∏–¥–µ–æ
export async function POST(request: NextRequest) {
  try {
    let generationId: string;
    let prompt: string;
    let modelName: string;
    let modelConfigStr: string;
    let videoCount: number;
    let status: string;
    let progress: number;
    let createdAt: string;
    let generationType: "text-to-video" | "image-to-video";
    let imageFile: File | null = null;
    let paymentSessionId: string | null = null;

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º Content-Type –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
    const contentType = request.headers.get("content-type");

    if (contentType?.includes("application/json")) {
      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
      const jsonData = await request.json();
      generationId = jsonData.generationId ?? `gen_${Date.now()}`;
      prompt = jsonData.prompt ?? "";
      modelName = jsonData.modelName ?? "Unknown Model";
      modelConfigStr = jsonData.modelConfig
        ? JSON.stringify(jsonData.modelConfig)
        : "{}";
      videoCount = jsonData.videoCount ?? 1;
      status = jsonData.status ?? "pending";
      progress = jsonData.progress ?? 0;
      createdAt = jsonData.createdAt ?? new Date().toISOString();
      generationType = jsonData.generationType ?? "text-to-video";
      paymentSessionId = jsonData.paymentSessionId ?? null;
    } else {
      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º FormData (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
      const formData = await request.formData();
      generationId = formData.get("generationId") as string;
      prompt = formData.get("prompt") as string;
      modelName = formData.get("modelName") as string;
      modelConfigStr = formData.get("modelConfig") as string;
      videoCount = parseInt(formData.get("videoCount") as string);
      status = formData.get("status") as string;
      progress = parseInt(formData.get("progress") as string);
      createdAt = formData.get("createdAt") as string;
      generationType = formData.get("generationType") as
        | "text-to-video"
        | "image-to-video";
      imageFile = formData.get("imageFile") as File | null;
      paymentSessionId = formData.get("paymentSessionId") as string;
    }

    console.log("üé¨ Model video generation request:", {
      generationId,
      prompt,
      modelName,
      generationType,
      hasImageFile: !!imageFile,
    });

    if (imageFile) {
      console.log("üé¨ Image file received:", {
        fileName: imageFile.name,
        fileType: imageFile.type,
        fileSize: imageFile.size,
      });
    }

    // –ü–∞—Ä—Å–∏–º modelConfig
    let modelConfig;
    try {
      modelConfig = JSON.parse(modelConfigStr);
    } catch {
      modelConfig = {};
    }

    // –í–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å–∞
    const validatedData = modelVideoGenerationSchema.parse({
      generationId: generationId || `gen_${Date.now()}`,
      prompt,
      modelName,
      modelConfig: modelConfig ?? {},
      videoCount: isNaN(videoCount) ? 1 : (videoCount ?? 1),
      status: status || "pending",
      progress: isNaN(progress) ? 0 : progress || 0,
      createdAt: createdAt || new Date().toISOString(),
      generationType,
      imageFile,
      paymentSessionId,
    });

    console.log("‚úÖ Validated data:", {
      generationType: validatedData.generationType,
      hasImageFile: !!validatedData.imageFile,
    });

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –ü–ï–†–ï–î –Ω–∞—á–∞–ª–æ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    const multipliers: string[] = [];

    // –ú–Ω–æ–∂–∏—Ç–µ–ª–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    const duration = modelConfig?.maxDuration ?? 8;
    if (duration <= 5) multipliers.push("duration-5s");
    else if (duration <= 10) multipliers.push("duration-10s");
    else if (duration <= 15) multipliers.push("duration-15s");
    else if (duration <= 30) multipliers.push("duration-30s");

    // –ú–Ω–æ–∂–∏—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    const width = modelConfig?.width ?? 1280;
    if (width >= 2160) {
      multipliers.push("4k-quality");
    } else {
      multipliers.push("hd-quality"); // HD –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    }

    // const operationType =
    //   generationType === "image-to-video" ? "image-to-video" : "text-to-video";

    // –°—Ç–∞–±–∏–ª—å–Ω—ã–π userId: cookie ‚Üí fallback IP
    const cookieUid = request.cookies.get("superduperai_uid")?.value;
    const forwarded = request.headers.get("x-forwarded-for");
    const realIp = request.headers.get("x-real-ip");
    const ip = forwarded?.split(",")[0]?.trim() ?? realIp ?? "unknown";
    const userId = cookieUid ? `demo-user-${cookieUid}` : `demo-user-${ip}`;

    console.log(
      `üé¨ Video generation API - uid: ${cookieUid ?? "(no-cookie)"}, ip: ${ip}, userId: ${userId}`
    );

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–ø–ª–∞—Ç—É –¥–ª—è –ø—Ä—è–º–æ–π –æ–ø–ª–∞—Ç—ã
    let sessionData: SessionData | null = null;
    if (paymentSessionId) {
      console.log("üí≥ Checking payment session:", paymentSessionId);

      // –ü–æ–ª—É—á–∞–µ–º session data –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
      sessionData = await getSessionData(paymentSessionId);
      if (sessionData) {
        console.log("üìä Retrieved session data:", {
          promptLength: sessionData.prompt.length,
          generationType: sessionData.generationType,
          modelName: sessionData.modelName,
        });

        // –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑ session data, –µ—Å–ª–∏ –æ–Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–∞
        if (sessionData.generationType) {
          generationType = sessionData.generationType as
            | "text-to-video"
            | "image-to-video";
          console.log(
            "üéØ Using generation type from session data:",
            generationType
          );
        }
      }
    } else {
      console.log(
        "‚ö†Ô∏è No payment session ID provided, but continuing for demo purposes"
      );
    }

    console.log("‚úÖ Starting video generation...");

    // –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –Ω–∞—à–µ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
    try {
      const _config = getSuperduperAIConfig();
      let result;

      // –ú–∞–ø–ø–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é SuperDuperAI
      const mappedModelName = mapModelNameToConfig(modelName, generationType);
      console.log(`üé¨ Model mapping details:`);
      console.log(`   Original: "${modelName}"`);
      console.log(`   Generation type: "${generationType}"`);
      console.log(`   Mapped to: "${mappedModelName}"`);

      // –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
      console.log("üé¨ Generation type analysis:", {
        generationType,
        hasImageFile: !!imageFile,
        sessionDataGenerationType: sessionData?.generationType,
      });

      if (generationType === "image-to-video" && imageFile) {
        // Image-to-video –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        console.log("üñºÔ∏è Starting image-to-video generation with file");
        console.log("üìÅ File details:", {
          fileName: imageFile.name,
          fileType: imageFile.type,
          fileSize: imageFile.size,
          hasFile: !!imageFile,
        });

        // –î–ª—è Sora –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è duration: 5, 10, 15, 20
        let duration = modelConfig?.maxDuration ?? 8;
        if (mappedModelName === "azure-openai/sora") {
          // –ë–ª–∏–∂–∞–π—à–µ–µ –¥–æ–ø—É—Å—Ç–∏–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è Sora
          if (duration <= 5) duration = 5;
          else if (duration <= 10) duration = 10;
          else if (duration <= 15) duration = 15;
          else duration = 20;
        }

        result = await generateVideoWithSuperDuperAI(
          prompt,
          modelName,
          {
            width: modelConfig?.width ?? 1280,
            height: modelConfig?.height ?? 720,
            aspectRatio: modelConfig?.aspectRatio ?? "16:9",
            duration: duration,
            frameRate: modelConfig?.frameRate ?? 30,
            style: "flux_watercolor",
            shotSize: "medium_shot",
          },
          imageFile,
          "image-to-video"
        );
      } else {
        // Text-to-video –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        console.log("üìù Starting text-to-video generation");

        // –î–ª—è Sora –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è duration: 5, 10, 15, 20
        let duration = modelConfig?.maxDuration ?? 8;
        if (mappedModelName === "azure-openai/sora") {
          // –ë–ª–∏–∂–∞–π—à–µ–µ –¥–æ–ø—É—Å—Ç–∏–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è Sora
          if (duration <= 5) duration = 5;
          else if (duration <= 10) duration = 10;
          else if (duration <= 15) duration = 15;
          else duration = 20;
        }

        result = await generateVideoWithSuperDuperAI(
          prompt,
          modelName,
          {
            width: modelConfig?.width ?? 1280,
            height: modelConfig?.height ?? 720,
            aspectRatio: modelConfig?.aspectRatio ?? "16:9",
            duration: duration,
            frameRate: modelConfig?.frameRate ?? 30,
            style: "flux_watercolor",
            shotSize: "medium_shot",
          },
          undefined,
          "text-to-video"
        );
      }

      if (!result.success) {
        throw new Error(result.error);
      }

      // –°–ø–∏—Å—ã–≤–∞–µ–º –±–∞–ª–∞–Ω—Å –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
      try {
        // await deductOperationBalance(
        //   userId, // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ userId –Ω–∞ –æ—Å–Ω–æ–≤–µ IP
        //   "video-generation",
        //   operationType,
        //   multipliers,
        //   {
        //     projectId: result.projectId,
        //     fileId: result.fileId,
        //     prompt: prompt.substring(0, 100),
        //     operationType,
        //     duration,
        //     resolution: `${width}x${modelConfig?.height || 720}`,
        //     timestamp: new Date().toISOString(),
        //   }
        // );
        // console.log(
        //   `üí≥ Balance deducted for user ${userId} after successful video generation`
        // );
      } catch (balanceError) {
        console.error(
          "‚ö†Ô∏è Failed to deduct balance after video generation:",
          balanceError
        );
        // –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–∞
      }

      // –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ —Å fileIds
      const videos = [
        {
          fileId: result.fileId!,
          status: "processing" as const,
          url: undefined,
          thumbnailUrl: undefined,
        },
      ];

      // –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å file IDs
      const updatedData: ModelVideoGenerationData = {
        ...validatedData,
        status: "processing",
        progress: 10, // –ù–∞—á–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
        videos,
      };

      // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ–±—â–µ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
      saveVideoGenerationData(updatedData);

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å
      console.log("üîç Verifying data was saved...");
      if (validatedData.generationId) {
        const savedData = loadVideoGenerationData(validatedData.generationId);
        console.log(
          "üîç Saved data verification:",
          savedData ? "SUCCESS" : "FAILED"
        );
      }

      console.log("üé¨ Model video generation started:", {
        success: true,
        generationId: validatedData.generationId,
        modelName: validatedData.modelName,
        fileId: result.fileId,
        status: "started",
        estimatedTime: validatedData.videoCount * 50, // 50 —Å–µ–∫—É–Ω–¥ –Ω–∞ –≤–∏–¥–µ–æ
        message: "Model video generation started",
      });

      return NextResponse.json({
        success: true,
        generationId: validatedData.generationId,
        taskId: result.fileId, // –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π fileId –∫–∞–∫ taskId
        modelName: validatedData.modelName,
        fileIds: [result.fileId],
        status: "started",
        estimatedTime: validatedData.videoCount * 50,
        message: "Model video generation started",
      });
    } catch (error) {
      console.error("‚ùå Model video generation error:", error);

      // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—à–∏–±–∫–∏
      const errorData: ModelVideoGenerationData = {
        ...validatedData,
        status: "error",
        error: error instanceof Error ? error.message : "Unknown error",
      };

      saveVideoGenerationData(errorData);

      return NextResponse.json(
        {
          success: false,
          error: "Failed to start video generation",
          details: error instanceof Error ? error.message : "Unknown error",
        },
        { status: 500 }
      );
    }
  } catch (error) {
    console.error("‚ùå Model video API error:", error);

    if (error instanceof z.ZodError) {
      return NextResponse.json(
        {
          success: false,
          error: "Invalid request data",
          details: error.errors,
        },
        { status: 400 }
      );
    }

    return NextResponse.json(
      {
        success: false,
        error: "Internal server error",
        details: error instanceof Error ? error.message : "Unknown error",
      },
      { status: 500 }
    );
  }
}

// GET - –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const generationId = searchParams.get("generationId");

    if (!generationId) {
      return NextResponse.json(
        {
          success: false,
          error: "Generation ID is required",
        },
        { status: 400 }
      );
    }

    // –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    const generationData = loadVideoGenerationData(generationId);

    if (!generationData) {
      return NextResponse.json(
        {
          success: false,
          error: "Generation not found",
        },
        { status: 404 }
      );
    }

    // –ï—Å–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ –µ—â–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å —á–µ—Ä–µ–∑ SuperDuperAI API
    if (generationData.status === "processing" && generationData.videos) {
      let allCompleted = true;
      let totalProgress = 0;
      const updatedVideos = [];

      for (const video of generationData.videos) {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∏–∑ generateVideoWithStrategy
        try {
          const { getSuperduperAIConfig } = await import(
            "@/lib/config/superduperai"
          );
          const config = getSuperduperAIConfig();

          const response = await fetch(
            `${config.url}/api/v1/file/${video.fileId}`,
            {
              headers: {
                Authorization: `Bearer ${config.token}`,
                "Content-Type": "application/json",
              },
            }
          );

          if (!response.ok) {
            console.error(
              `‚ùå Failed to check file ${video.fileId} status:`,
              response.status
            );
            updatedVideos.push({
              ...video,
              status: "error" as const,
            });
            totalProgress += 0;
            allCompleted = false;
            continue;
          }

          const fileData = await response.json();
          console.log(`üìÅ File ${video.fileId} status:`, fileData);

          // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à–µ–Ω –ª–∏ —Ñ–∞–π–ª
          if (fileData.url) {
            updatedVideos.push({
              ...video,
              url: fileData.url,
              thumbnailUrl: fileData.thumbnail_url,
              status: "completed" as const,
            });
            totalProgress += 100;
          } else {
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
            if (fileData.tasks && fileData.tasks.length > 0) {
              const latestTask = fileData.tasks[fileData.tasks.length - 1];
              if (latestTask.status === "error") {
                updatedVideos.push({
                  ...video,
                  status: "error" as const,
                });
                totalProgress += 0;
                allCompleted = false;
              } else if (latestTask.status === "in_progress") {
                updatedVideos.push({
                  ...video,
                  status: "processing" as const,
                });
                totalProgress += 50; // –í—Å–µ –µ—â–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è
                allCompleted = false;
              } else {
                updatedVideos.push({
                  ...video,
                  status: "processing" as const,
                });
                totalProgress += 50;
                allCompleted = false;
              }
            } else {
              updatedVideos.push({
                ...video,
                status: "processing" as const,
              });
              totalProgress += 50;
              allCompleted = false;
            }
          }
        } catch (error) {
          console.error(`‚ùå Error checking file ${video.fileId}:`, error);
          updatedVideos.push({
            ...video,
            status: "error" as const,
          });
          totalProgress += 0;
          allCompleted = false;
        }
      }

      const averageProgress = Math.round(
        totalProgress / generationData.videos.length
      );

      // –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
      const updatedData: ModelVideoGenerationData = {
        ...generationData,
        status: allCompleted ? "completed" : "processing",
        progress: averageProgress,
        videos: updatedVideos,
      };

      saveVideoGenerationData(updatedData);

      return NextResponse.json({
        success: true,
        ...updatedData,
      });
    }

    return NextResponse.json({
      success: true,
      ...generationData,
    });
  } catch (error) {
    console.error("‚ùå Status check error:", error);

    return NextResponse.json(
      {
        success: false,
        error: "Failed to check generation status",
        details: error instanceof Error ? error.message : "Unknown error",
      },
      { status: 500 }
    );
  }
}
